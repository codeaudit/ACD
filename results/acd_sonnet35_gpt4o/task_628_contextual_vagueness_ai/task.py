import random

class TaskFamily:
    @staticmethod
    def get_tasks() -> dict[str, dict]:
        scenarios = [
            {
                "domain": "weather forecasting",
                "vague_term": "warm",
                "contexts": ["Arctic winter", "Mediterranean summer"]
            },
            {
                "domain": "product reviews",
                "vague_term": "expensive",
                "contexts": ["luxury watches", "fast food meals"]
            }
        ]
        return {
            "1": random.choice(scenarios),
            "2": random.choice(scenarios)
        }

    @staticmethod
    def get_instructions(t: dict) -> str:
        return f"""Design an AI system capable of generating and interpreting context-dependent vague language, then apply it to the following scenario:

Domain: {t['domain']}
Vague term: '{t['vague_term']}'
Contexts: {t['contexts'][0]} and {t['contexts'][1]}

Your task has the following parts:

1. System Architecture (200-250 words):
   a) Describe the key components of your AI system for generating and interpreting context-dependent vague language.
   b) Explain how your system incorporates contextual information and linguistic knowledge.
   c) Discuss any novel elements in your design that enable context-sensitive interpretation of vague terms.

2. Cognitive Modeling (150-200 words):
   a) Explain how your system models the cognitive processes involved in human interpretation of vague language.
   b) Describe how your model accounts for individual and cultural differences in vagueness interpretation.

3. Contextual Application (200-250 words):
   a) Apply your AI system to interpret the vague term '{t['vague_term']}' in both given contexts.
   b) Explain how the system's interpretation differs between the two contexts.
   c) Provide example outputs of how your system would use the vague term in sentences for each context.

4. Vagueness Generation (150-200 words):
   a) Describe how your system would generate vague language appropriate to the given domain and contexts.
   b) Provide an example of a vague statement generated by your system for each context.
   c) Explain how your system ensures the generated vagueness is appropriate and effective.

5. Evaluation Methodology (100-150 words):
   a) Propose a method to evaluate the effectiveness and contextual appropriateness of your system's vagueness interpretation and generation.
   b) Describe metrics you would use to assess both linguistic accuracy and cognitive plausibility.

6. Ethical Considerations (100-150 words):
   a) Discuss potential ethical implications of using AI for generating and interpreting vague language.
   b) Propose safeguards or guidelines to ensure responsible use of such a system.

Ensure your response demonstrates a deep understanding of linguistics, cognitive science, and AI systems. Use technical terminology appropriately and provide explanations where necessary. Be creative in your approach while maintaining scientific and technological plausibility.

Format your response using clear headings for each section."""

    @staticmethod
    def score(t: dict, submission: str) -> float | None:
        from src.eval_helper import eval_with_llm_judge
        instructions = TaskFamily.get_instructions(t)
        criteria = [
            "The response demonstrates a deep understanding of vagueness in language and its context-dependent nature.",
            "The proposed AI system architecture is well-designed and incorporates relevant linguistic and cognitive principles.",
            "The cognitive modeling component accurately reflects human processing of vague language.",
            "The system's application to the given scenarios is logical and demonstrates clear context-sensitivity.",
            "The vagueness generation examples are appropriate and creative.",
            "The evaluation methodology and ethical considerations are well-thought-out and relevant.",
            "The overall response shows strong interdisciplinary integration of linguistics, cognitive science, and AI."
        ]
        return 1.0 if eval_with_llm_judge(instructions, submission, criteria) else 0.0
